#+options: toc:nil
#+options: stat:nil
#+options: todo:nil
* A practical checklist for building distributed systems [3/9]
** DONE Introduction
When I worked at Form3--particularly during a period when I was designing a new payments system--I worked with several teams of engineers to design new components in a highly distributed system. The software components themselves were distributed; running in several different locations, with lots of asynchronous inputs. However, their underlying platform was also distributed; relying on [[https://www.cockroachlabs.com/][CockroachDB]] for data storage, and [[https://docs.nats.io/nats-concepts/jetstream][JetStream]] for messaging.

There are many traps it's easy to fall into when building new components in an environment like this. Sometimes we would catch these early in the design process, and sometimes they would be caught later during peer review. Occasionally they didn't come up until we started performing load and chaos testing on the system. Luckily none of them made their way to production ðŸ˜…

As we iterated on our design process--which we repeated many times as the payments system took shape--we created a checklist of ideas to consider when designing a new part of the system. I thought this was an incredibly valuable prompt for conversations about the draft design; it ensured we considered what we planning from a variety of different angles and failure scenarios, before we'd even begun to write the code.

Below is a list of the main items that were on the checklist, with a description of why its valuable, and its context for designing distributed systems. I hope this prompts some interesting questions for you, whenever you're designing distributed systems in the future.
** DONE Network boundaries and failure
In any distributed system, there will be network boundaries between components. These might be HTTP requests one program makes to another, database connections, or publication/consumption of messages to a broker. Each of these network boundaries introduces a significant source of failure, so any design that introduces new network boundaries should carefully consider how failure will also be managed.

Let me give two simple examples of how you might decide to handle failure. First, let's say you're introducing a feature which will make an HTTP request to an external system when it processes a message from a queue:

#+begin_src plantuml :file distributed-systems-checklist-message-to-http-failure.png
@startuml
queue "Queue" as q
node "Application" as app
cloud "3rd party" as ext
q -> app
app --> app : Processing
app --> ext : HTTP
@enduml
#+end_src

#+RESULTS:
[[file:distributed-systems-checklist-message-to-http-failure.png]]

Typically, a message broker that asynchronously delivers messages to your application will have a robust mechanism for retrying the delivery of messages, and eventually doing something with them if they continually fail (e.g. sending them to a dead-letter queue). In this case, the simplest way of dealing with failure at the HTTP boundary is to fail the entire processing pipeline, and rely on the message's delivery being retried by the message broker.

Another example is of an application whose inputs are HTTP requests, with an upstream network boundary to a database:

#+begin_src plantuml :file distributed-systems-checklist-http-to-database-failure.png
@startuml
circle "Client" as c
node "Application" as app
database "Database" as db

c -> app : HTTP
app -> app : Processing
app --> db : TCP
@enduml
#+end_src

#+RESULTS:
[[file:distributed-systems-checklist-http-to-database-failure.png]]

If there is a problem with the TCP connection between the application and its database, processing the HTTP request might fail (e.g. inserting a record in the database). In this case, the simplest way to deal with database-level failure would be to simply return a descriptive status code to the client, e.g. a 500. Returning a failure code like this assumes the client will retry the input request in the future.

However, things get more difficult if these examples get a little more complex:

#+begin_src plantuml :file distributed-systems-checklist-multi-step-failure.png
@startuml
queue "Input Queue" as q
queue "Output Queue" as q2
node "Application" as app
database "Database" as db
cloud "3rd party" as ext
node "Internal API" as api

q -> app
app -> app : Processing
app --> ext : HTTP
app --> api : HTTP
app --> q2
app --> db : TCP
@enduml
#+end_src

#+RESULTS:
[[file:distributed-systems-checklist-multi-step-failure.png]]

In this example, when the application processes a message from the input queue, it does several things in succession. It publishes a message to an output queue, writes to a database, sends an HTTP request to a third party, and sends an HTTP request to an internal API. Any one of these network boundaries could cause a failure, so simply relying on retries originating from the input queue isn't enough.

In addition to identifying network boundaries as a source of failure, we also need to consider idempotency, retry logic, and duplicate checking.
** DONE Idempotency, retries, and duplicate checking
In the example above, there are two ways of dealing with failure at each of the network boundaries:

1. Retry the network communication in-process until it is successful.
2. Fail the entire pipeline of processing back to the input message, and retry all the network I/O.

In practice, a combination of the two approaches is often necessary. Communication over each boundary could be retried over a short timescale to see if this results in successful communication. For example, if sending the HTTP request to the internal API fails, the application could retry it 5 times every 100 ms. However, a long duration of retries (e.g. an exponential backoff lasting several seconds) puts the operation at risk of being interrupted (e.g. by a termination signal). If the failure cannot be mitigated by short-term retries, then the entire pipeline should be aborted; this relies on the initial message queue boundary to retry the segment of processing which includes this gauntlet of network I/O.

This could be dangerous if not done carefully. Duplicate messages could be sent to the output queue, duplicate records written to the database, and multiple resources created in upstream APIs when one is expected. In order to retry the network I/O safely, each network boundary must have logic that ensures it is idempotent. For example:

- Messages sent to a message queue should have an immutable identifier that won't change if they are re-sent in the future.
- Records written to a database should have a deterministic primary key, such that inserting them more than once will fail.
- Resources created in an API should have the same ID on every attempt, so that the upstream API can determine if the resource has been created in the past.

This should make your application very robust to retrying its communication over network boundaries. Sometimes it is difficult to get this right when dealing with third party systems, but most of the time they have a mechanism for your to build your client in an idempotent way.
** TODO Disaster recovery
** TODO Horizontal scaling, and possible processing bottlenecks
** TODO Interfaces with third parties
** TODO Shared state, storage, and consensus
** TODO Graceless process termination
** TODO Summary
